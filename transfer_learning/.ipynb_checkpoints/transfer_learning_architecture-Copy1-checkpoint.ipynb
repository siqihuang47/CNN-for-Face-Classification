{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_cnn import *\n",
    "from datetime import datetime\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2zG_gzb9nXB"
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        #nn.init.xavier_normal_(m.weight.data)\n",
    "    #elif classname.find('Linear') != -1:\n",
    "     #   nn.init.xavier_normal_(m.weight.data)\n",
    "    \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "    elif classname.find('Linear') != -1:\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "    \n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yNLkDijm9oJF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is supported\n",
      "Nnet(\n",
      "  (main): Sequential(\n",
      "    (0): Conv2d(3, 21, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(21, 20, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Conv2d(20, 15, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (6): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(15, 7, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (9): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU(inplace)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=343, out_features=500, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Linear(in_features=500, out_features=201, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if your system supports CUDA\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Setup GPU optimization if CUDA is supported\n",
    "if use_cuda:\n",
    "    computing_device = torch.device(\"cuda\")\n",
    "    extras = {\"num_workers\": 1, \"pin_memory\": True}\n",
    "    print(\"CUDA is supported\")\n",
    "else: # Otherwise, train on the CPU\n",
    "    computing_device = torch.device(\"cpu\")\n",
    "    extras = False\n",
    "    print(\"CUDA NOT supported\")\n",
    "\n",
    "net=Nnet().to(computing_device)\n",
    "net.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(net)\n",
    "\n",
    "#loss criteria are defined in the torch.nn package\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Instantiate the gradient descent optimizer - use Adam optimizer with default parameters\n",
    "optimizer = optim.Adam(net.parameters(),lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_classes(dataset, num_classes):\n",
    "    count = [0] * num_classes\n",
    "    \n",
    "    for image, label in dataset:\n",
    "#         label = item\n",
    "#         print(label)\n",
    "\n",
    "        # labels are 1-100, indices are 0-199\n",
    "        # keep track of number of images for each class\n",
    "        #print(label, end='\\r')\n",
    "        count[label - 1] += 1\n",
    "        \n",
    "    balancer = [0.] * num_classes\n",
    "    total_images = float(len(dataset))\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        balancer[i] = total_images / float(count[i])\n",
    "    \n",
    "    weights = [0] * len(dataset)\n",
    "    \n",
    "    for i, (image, label) in enumerate(dataset):\n",
    "\n",
    "        weights[i] = balancer[label - 1]\n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_images(dataset, indices):\n",
    "    chosen = [dataset[i] for i in indices]\n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor()])\n",
    "dataset = loader('../train.csv','/datasets/cs154-fa19-public/',transform=transform)\n",
    "batch_size = 64\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "    \n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "dataset_sizes = {\"train\": dataset_size * 0.8, \"val\": split}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = choose_images(dataset, train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights = balance_classes(train_data, 200)\n",
    "#weights = torch.DoubleTensor(weights)\n",
    "\n",
    "#train_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights))\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    losses = {\"train\": [], \"val\": []}\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            count = 0\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                print('batch {}'.format(count), end=\"\\r\", flush=True)\n",
    "                count += 1\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            losses[phase].append(epoch_loss)\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        time_elapsed = time.time() - epoch_start\n",
    "        print('Epoch complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "        print()\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for calculating accuracy\n",
    "def calculate_accu(outputs, labels, batch_size):\n",
    "    num_correct = torch.sum(torch.max(outputs, dim = 1)[1] == labels).item()\n",
    "    return num_correct / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import copy\n",
    "# Track the loss across training\n",
    "total_loss = []\n",
    "total_accu = []\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "avg_minibatch_loss = []\n",
    "avg_minibatch_accu = []\n",
    "N = 50\n",
    "\n",
    "all_models = []\n",
    "\n",
    "valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "\n",
    "early_stop_counter = 0  # track number of epochs where val loss increases\n",
    "for epoch in range(50):\n",
    "    epoch_start_time = datetime.now()\n",
    "    N_minibatch_loss = 0.0\n",
    "    N_minibatch_accu = 0.0\n",
    "\n",
    "    # Get the next minibatch of images, labels for training\n",
    "    for minibatch_count, (images, labels) in enumerate(train_loader, 0):\n",
    "        print(\"mini_batch\", minibatch_count)\n",
    "        # Zero out the stored gradient (buffer) from the previous iteration\n",
    "        optimizer.zero_grad()\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "        # Perform the forward pass through the network and compute the loss\n",
    "        outputs = net(images)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        accu = calculate_accu(outputs, labels, batch_size)\n",
    "        # Automagically compute the gradients and backpropagate the loss through the network\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()    \n",
    "        # Add this iteration's loss to the total_loss\n",
    "        total_loss.append(loss.item())\n",
    "        total_accu.append(accu)\n",
    "        \n",
    "        N_minibatch_loss += loss.item()\n",
    "        N_minibatch_accu += accu\n",
    "        \n",
    "        if minibatch_count % N == 49:\n",
    "            #Print the loss averaged over the last N mini-batches\n",
    "            N_minibatch_loss /= N\n",
    "            N_minibatch_accu /= N\n",
    "            \n",
    "            print('Epoch %d, average minibatch %d loss: %.3f' % (epoch + 1, minibatch_count+1, N_minibatch_loss))\n",
    "            # Add the averaged loss over N minibatches and reset the counter\n",
    "            avg_minibatch_loss.append(N_minibatch_loss)\n",
    "            avg_minibatch_accu.append(N_minibatch_accu)\n",
    "            \n",
    "            N_minibatch_loss = 0.0\n",
    "            N_minibatch_accu = 0.0\n",
    "    \n",
    "    train_losses.append(np.average(total_loss))\n",
    "    train_accuracies.append(np.average(total_accu))\n",
    "    \n",
    "    # TODO: Implement validation \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        valid_loss = 0\n",
    "        valid_accu = 0\n",
    "        \n",
    "        for minibatch_count, (images, labels) in enumerate(validation_loader, 0):\n",
    "            \n",
    "            #Apply current model to the data\n",
    "            images, labels = images.to(computing_device), labels.to(computing_device)\n",
    "            outputs = net(images)\n",
    "            \n",
    "            valid_accu += calculate_accu(outputs, labels, batch_size)\n",
    "            valid_loss += criterion(outputs, labels).item()\n",
    "        \n",
    "        avg_valid_accu = valid_accu/minibatch_count\n",
    "        avg_valid_loss = valid_loss/minibatch_count\n",
    "        \n",
    "        print(\"Valid loss for validation set is \", avg_valid_loss, \"%.\")\n",
    "        print(\"Accuracy for validation set is\", avg_valid_accu * 100, \"%.\")\n",
    "        \n",
    "        all_models.append(copy.deepcopy(net))\n",
    "        \n",
    "        if not valid_losses:\n",
    "            model = copy.deepcopy(net)\n",
    "        elif avg_valid_loss > valid_losses[-1]:\n",
    "            early_stop_counter += 1\n",
    "            \n",
    "            valid_losses.append(avg_valid_loss)\n",
    "            valid_accuracies.append(avg_valid_accu)\n",
    "            if early_stop_counter == 2:\n",
    "                print(\"stopped\")\n",
    "                break\n",
    "        elif avg_valid_loss < min(valid_losses):\n",
    "            model = copy.deepcopy(net)\n",
    "        early_stop_counter = 0\n",
    "        \n",
    "        valid_losses.append(avg_valid_loss)\n",
    "        valid_accuracies.append(avg_valid_accu)\n",
    "    end_time = datetime.now()\n",
    "    \n",
    "    epoch_runtime = end_time - epoch_start_time\n",
    "    print(\"epoch {} time: {}\".format(epoch, epoch_runtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, \"trained_model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Model On the Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"transfer_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test set\n",
    "test_dataset = loader('../test.csv','/datasets/cs154-fa19-public/',\n",
    "                      transform = transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set Preformance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "\n",
    "#model for performance\n",
    "def per_class_model_performance(performances):\n",
    "    \n",
    "    perf_df = []\n",
    "    \n",
    "    #for each class, calculate accuracy, recall, precision and bcr\n",
    "    for i in range(len(performances)):\n",
    "        \n",
    "        cur_perf = performances[i]\n",
    "        accu, recall, precision, bcr = get_per_class_values(cur_perf)\n",
    "        \n",
    "        perf_df.append([accu, precision, recall, bcr])\n",
    "        \n",
    "    #make it to a dataframe\n",
    "    perf_df = pd.DataFrame(perf_df)\n",
    "    perf_df.columns = ['Accuracy', 'Precision', 'Recall', 'BCR']\n",
    "    \n",
    "    return perf_df\n",
    " \n",
    "\n",
    "#get measurement recall, accuracy, precision and bcr value for the current class\n",
    "def get_per_class_values(cur_perf):    \n",
    "    \n",
    "    tp = cur_perf['TP']\n",
    "    fp = cur_perf['FP']\n",
    "    tn = cur_perf['TN']\n",
    "    fn = cur_perf['FN']\n",
    "    \n",
    "    #accuracy\n",
    "    accu = (tp + tn)/(tp + tn + fp + fn)\n",
    "    \n",
    "    #recall\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    #precision\n",
    "    if fp + tp == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (fp + tp)\n",
    "        \n",
    "    #bcr\n",
    "    bcr = (precision + recall) / 2\n",
    "    \n",
    "    return accu, recall, precision, bcr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current minibatch:  0 \n",
      "current minibatch:  1 \n",
      "current minibatch:  2 \n",
      "current minibatch:  3 \n",
      "current minibatch:  4 \n",
      "current minibatch:  5 \n",
      "current minibatch:  6 \n",
      "current minibatch:  7 \n",
      "current minibatch:  8 \n",
      "current minibatch:  9 \n",
      "current minibatch:  10 \n",
      "current minibatch:  11 \n",
      "current minibatch:  12 \n",
      "current minibatch:  13 \n",
      "current minibatch:  14 \n",
      "current minibatch:  15 \n",
      "current minibatch:  16 \n",
      "current minibatch:  17 \n",
      "current minibatch:  18 \n",
      "current minibatch:  19 \n",
      "current minibatch:  20 \n",
      "current minibatch:  21 \n",
      "current minibatch:  22 \n",
      "current minibatch:  23 \n",
      "current minibatch:  24 \n",
      "current minibatch:  25 \n",
      "current minibatch:  26 \n",
      "current minibatch:  27 \n",
      "current minibatch:  28 \n",
      "current minibatch:  29 \n",
      "current minibatch:  30 \n",
      "current minibatch:  31 \n",
      "current minibatch:  32 \n",
      "current minibatch:  33 \n",
      "current minibatch:  34 \n",
      "current minibatch:  35 \n",
      "current minibatch:  36 \n",
      "current minibatch:  37 \n",
      "current minibatch:  38 \n",
      "current minibatch:  39 \n",
      "current minibatch:  40 \n",
      "current minibatch:  41 \n",
      "current minibatch:  42 \n",
      "current minibatch:  43 \n",
      "current minibatch:  44 \n",
      "current minibatch:  45 \n",
      "current minibatch:  46 \n",
      "current minibatch:  47 \n",
      "current minibatch:  48 \n",
      "current minibatch:  49 \n",
      "current minibatch:  50 \n"
     ]
    }
   ],
   "source": [
    "#Apply to test set and test Performances\n",
    "all_class_performance = []\n",
    "test_accuracies = []\n",
    "\n",
    "#turn list into a sparse matrix\n",
    "def make_matrix(lst):\n",
    "    mat = []\n",
    "    for i in lst:\n",
    "        cur = [0] * 201\n",
    "        cur[i] = 1\n",
    "        mat.append(cur)\n",
    "    return np.array(mat)\n",
    "\n",
    "\n",
    "for i in range(201):\n",
    "    all_class_performance.append({'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0})\n",
    "\n",
    "with torch.no_grad(): \n",
    "    \n",
    "    test_accu = 0\n",
    "    \n",
    "    for minibatch_count, (images, labels) in enumerate(test_loader, 0):\n",
    "        \n",
    "        print(\"current minibatch: \", minibatch_count, '\\r')\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device) \n",
    "        outputs = model(images)\n",
    "        \n",
    "        test_accu += calculate_accu(outputs, labels, batch_size)\n",
    "        \n",
    "        predictions = torch.max(outputs, dim = 1)[1]\n",
    "\n",
    "        pred = make_matrix(predictions.tolist())\n",
    "        lab = make_matrix(labels.tolist())\n",
    "\n",
    "        for i in range(pred.shape[0]):\n",
    "            for j in range(201):\n",
    "                if (pred[i][j] == 1) and (lab[i][j] == 1):\n",
    "                    all_class_performance[j]['TP'] += 1\n",
    "                elif (pred[i][j] == 1) and (lab[i][j] == 0):\n",
    "                    all_class_performance[j]['FP'] += 1\n",
    "                elif (pred[i][j] == 0) and (lab[i][j] == 0):\n",
    "                    all_class_performance[j]['TN'] += 1\n",
    "                else:\n",
    "                    all_class_performance[j]['FN'] += 1\n",
    "                    \n",
    "    test_accuracies = (test_accu/minibatch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>BCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.977132</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.434451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998146</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.996292</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.995983</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.581250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.995983</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.519231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.999073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.993201</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.614194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.996601</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.996292</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.820106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.995983</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.170455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.998455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.996292</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.410256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.988257</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.434211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.999073</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.993820</td>\n",
       "      <td>0.481481</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.582846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.995674</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.472727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.996292</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.993201</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.996601</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.490385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.995056</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.987639</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.311828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.983622</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.420170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.991656</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.275298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.982695</td>\n",
       "      <td>0.186047</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.230954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.673797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.998455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.993820</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.413194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.996601</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.764444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.990729</td>\n",
       "      <td>0.439024</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.579512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.902256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.551378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.991347</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.522837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.996601</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.547619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.998455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.994747</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.640909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.361111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.991347</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.693333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.989493</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.555195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.996910</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.999691</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.994129</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.652899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.996601</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.627404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>0.996601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.995056</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.343750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.995365</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.993820</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.470356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.992583</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.123810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.990420</td>\n",
       "      <td>0.419355</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.459677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.995056</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.580556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.997528</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>0.997528</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.997837</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.611111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.995056</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.653409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.999382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.995674</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.564706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Accuracy  Precision    Recall       BCR\n",
       "0    1.000000   0.000000  0.000000  0.000000\n",
       "1    0.977132   0.243902  0.625000  0.434451\n",
       "2    0.998146   1.000000  0.333333  0.666667\n",
       "3    0.996292   0.600000  0.428571  0.514286\n",
       "4    0.995983   0.562500  0.600000  0.581250\n",
       "5    0.995983   0.500000  0.538462  0.519231\n",
       "6    0.999073   1.000000  0.727273  0.863636\n",
       "7    0.993201   0.548387  0.680000  0.614194\n",
       "8    0.996601   0.400000  0.200000  0.300000\n",
       "9    0.996292   0.714286  0.925926  0.820106\n",
       "10   0.995983   0.250000  0.090909  0.170455\n",
       "11   0.998455   1.000000  0.375000  0.687500\n",
       "12   0.996292   0.666667  0.153846  0.410256\n",
       "13   0.988257   0.368421  0.500000  0.434211\n",
       "14   0.999073   0.800000  0.666667  0.733333\n",
       "15   0.993820   0.481481  0.684211  0.582846\n",
       "16   0.995674   0.545455  0.400000  0.472727\n",
       "17   0.996292   0.500000  0.500000  0.500000\n",
       "18   0.993201   0.500000  0.500000  0.500000\n",
       "19   0.996601   0.750000  0.230769  0.490385\n",
       "20   0.995056   0.500000  0.625000  0.562500\n",
       "21   0.987639   0.333333  0.290323  0.311828\n",
       "22   0.983622   0.309091  0.531250  0.420170\n",
       "23   0.991656   0.312500  0.238095  0.275298\n",
       "24   0.982695   0.186047  0.275862  0.230954\n",
       "25   0.996910   0.818182  0.529412  0.673797\n",
       "26   0.998455   0.000000  0.000000  0.000000\n",
       "27   0.993820   0.388889  0.437500  0.413194\n",
       "28   0.996601   0.640000  0.888889  0.764444\n",
       "29   0.990729   0.439024  0.720000  0.579512\n",
       "..        ...        ...       ...       ...\n",
       "171  0.998764   0.857143  0.947368  0.902256\n",
       "172  0.994438   0.578947  0.523810  0.551378\n",
       "173  0.991347   0.468750  0.576923  0.522837\n",
       "174  0.996910   0.666667  0.333333  0.500000\n",
       "175  0.996601   0.666667  0.428571  0.547619\n",
       "176  0.998455   1.000000  0.545455  0.772727\n",
       "177  0.994747   0.600000  0.681818  0.640909\n",
       "178  0.997219   0.500000  0.222222  0.361111\n",
       "179  0.991347   0.520000  0.866667  0.693333\n",
       "180  0.989493   0.431818  0.678571  0.555195\n",
       "181  0.996910   0.000000  0.000000  0.000000\n",
       "182  0.996910   1.000000  0.090909  0.545455\n",
       "183  0.999691   0.857143  1.000000  0.928571\n",
       "184  0.994129   0.566667  0.739130  0.652899\n",
       "185  0.996601   0.692308  0.562500  0.627404\n",
       "186  0.996910   0.666667  1.000000  0.833333\n",
       "187  0.996601   0.000000  0.000000  0.000000\n",
       "188  0.995056   0.500000  0.187500  0.343750\n",
       "189  0.995365   0.500000  0.066667  0.283333\n",
       "190  0.993820   0.636364  0.304348  0.470356\n",
       "191  0.992583   0.200000  0.047619  0.123810\n",
       "192  0.990420   0.419355  0.500000  0.459677\n",
       "193  0.996910   0.000000  0.000000  0.000000\n",
       "194  0.995056   0.550000  0.611111  0.580556\n",
       "195  0.997528   0.636364  0.636364  0.636364\n",
       "196  0.997528   0.500000  0.125000  0.312500\n",
       "197  0.997837   1.000000  0.222222  0.611111\n",
       "198  0.995056   0.625000  0.681818  0.653409\n",
       "199  0.999382   1.000000  0.666667  0.833333\n",
       "200  0.995674   0.600000  0.529412  0.564706\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_model_performance(all_class_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Loss Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-034f73786d7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Training Losses'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_losses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Validation Losses'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m ax.set(xlabel='Number of Epochs', ylabel='Losses',\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_losses' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_title = 'Training vs Validation Losses for Baseline CNN with Early Stopping'\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.subplot()\n",
    "ax.plot(np.arange(1, len(train_losses) + 1), train_losses, label='Training Losses')\n",
    "ax.plot(np.arange(1, len(valid_losses) + 1), valid_losses, label='Validation Losses')\n",
    "ax.set(xlabel='Number of Epochs', ylabel='Losses',\n",
    "           title=graph_title)\n",
    "leg = ax.legend(loc=4)\n",
    "fig.savefig('graphs/baseline_train_vad_loss.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot on Training and Testing Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_title = 'Training vs Validation Accuracies for for Baseline CNN with Early Stopping'\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.subplot()\n",
    "ax.plot(np.arange(1, len(train_accuracies) + 1), np.array(train_accuracies) * 100, label='Training Accuracies(%)')\n",
    "ax.plot(np.arange(1, len(valid_accuracies) + 1), np.array(valid_accuracies) * 100, label='Validation Accuracies(%)')\n",
    "ax.set(xlabel='Number of Epochs', ylabel='Accuracy(%)',\n",
    "           title=graph_title)\n",
    "leg = ax.legend(loc=4)\n",
    "fig.savefig('graphs/baseline_train_test_accu.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The test accuracy is ' + str(test_accu/minibatch_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "batch 274\r"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "model_ft.fc = nn.Linear(num_ftrs, 201)\n",
    "# nn.Sequential(\n",
    "#     nn.Linear(num_ftrs, 420),\n",
    "#     nn.ReLU(inplace=True),\n",
    "#     nn.Linear(420, 201),\n",
    "# )\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer_conv = optim.SGD(model_ft.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "dataloaders = {'train': train_loader, 'val': validation_loader}\n",
    "model_conv, losses = train_model(model_ft, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_conv, \"transfer_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = torch.load(\"transfer_trained.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = loader('../test.csv','/datasets/cs154-fa19-public/',\n",
    "                      transform = transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                          batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44875 minibatch:  50\n"
     ]
    }
   ],
   "source": [
    "#Apply to test set and test Performances\n",
    "all_class_performance = []\n",
    "test_accuracies = []\n",
    "\n",
    "#turn list into a sparse matrix\n",
    "def make_matrix(lst):\n",
    "    mat = []\n",
    "    for i in lst:\n",
    "        cur = [0] * 201\n",
    "        cur[i] = 1\n",
    "        mat.append(cur)\n",
    "    return np.array(mat)\n",
    "\n",
    "\n",
    "for i in range(201):\n",
    "    all_class_performance.append({'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0})\n",
    "\n",
    "with torch.no_grad(): \n",
    "    \n",
    "    test_accu = 0\n",
    "    \n",
    "    for minibatch_count, (images, labels) in enumerate(test_loader, 0):\n",
    "        \n",
    "        print(\"current minibatch: \", minibatch_count, end='\\r')\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(computing_device), labels.to(computing_device) \n",
    "        outputs = model_conv(images)\n",
    "        \n",
    "        test_accu += calculate_accu(outputs, labels, batch_size)\n",
    "        \n",
    "        predictions = torch.max(outputs, dim = 1)[1]\n",
    "\n",
    "        pred = make_matrix(predictions.tolist())\n",
    "        lab = make_matrix(labels.tolist())\n",
    "\n",
    "        for i in range(pred.shape[0]):\n",
    "            for j in range(201):\n",
    "                if (pred[i][j] == 1) and (lab[i][j] == 1):\n",
    "                    all_class_performance[j]['TP'] += 1\n",
    "                elif (pred[i][j] == 1) and (lab[i][j] == 0):\n",
    "                    all_class_performance[j]['FP'] += 1\n",
    "                elif (pred[i][j] == 0) and (lab[i][j] == 0):\n",
    "                    all_class_performance[j]['TN'] += 1\n",
    "                else:\n",
    "                    all_class_performance[j]['FN'] += 1\n",
    "                    \n",
    "    test_accuracies = (test_accu/minibatch_count)\n",
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = per_class_model_performance(all_class_performance)\n",
    "metrics_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(df):\n",
    "    sorted_accs = df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "    top_5 = sorted_accs[1:6]\n",
    "    bot_5 = sorted_accs[-5:]\n",
    "    return top_5, bot_5\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Accuracy  Precision    Recall       BCR\n",
      "134  0.999691   0.933333  1.000000  0.966667\n",
      "14   0.999073   1.000000  0.500000  0.750000\n",
      "156  0.998455   1.000000  0.166667  0.583333\n",
      "56   0.998455   0.833333  0.555556  0.694444\n",
      "49   0.998455   0.857143  0.600000  0.728571\n",
      "     Accuracy  Precision    Recall       BCR\n",
      "22   0.983004   0.290909  0.500000  0.395455\n",
      "93   0.982695   0.245283  0.448276  0.346779\n",
      "1    0.982386   0.280702  0.500000  0.390351\n",
      "109  0.982386   0.245283  0.433333  0.339308\n",
      "37   0.977750   0.243902  0.666667  0.455285\n"
     ]
    }
   ],
   "source": [
    "top, bottom = get_values(metrics_df)\n",
    "print(top)\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_title = 'Training vs Validation Losses for Transfer Learning on Resnet with balance classes'\n",
    "train_losses = losses[\"train\"]\n",
    "valid_losses = losses['val']\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = plt.subplot()\n",
    "ax.plot(np.arange(1, len(train_losses) + 1), train_losses, label='Training Losses')\n",
    "ax.plot(np.arange(1, len(valid_losses) + 1), valid_losses, label='Validation Losses')\n",
    "ax.set(xlabel='Number of Epochs', ylabel='Losses',\n",
    "           title=graph_title)\n",
    "leg = ax.legend(loc=4)\n",
    "fig.savefig('graphs/baseline_train_vad_loss_balanced.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "cnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
