{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7_00PM is the best model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_copy2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/datasets/home/15/015/kzsidiqi/.conda/envs/pas/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/datasets/home/15/015/kzsidiqi/.conda/envs/pas/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/datasets/home/15/015/kzsidiqi/.conda/envs/pas/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/datasets/home/15/015/kzsidiqi/.conda/envs/pas/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.SELU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/datasets/home/15/015/kzsidiqi/.conda/envs/pas/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/datasets/home/15/015/kzsidiqi/.conda/envs/pas/lib/python3.6/site-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current minibatch:  0\n",
      "current minibatch:  1\n",
      "current minibatch:  2\n",
      "current minibatch:  3\n",
      "current minibatch:  4\n",
      "current minibatch:  5\n",
      "current minibatch:  6\n",
      "current minibatch:  7\n",
      "current minibatch:  8\n",
      "current minibatch:  9\n",
      "current minibatch:  10\n",
      "current minibatch:  11\n",
      "current minibatch:  12\n",
      "current minibatch:  13\n",
      "current minibatch:  14\n",
      "current minibatch:  15\n",
      "current minibatch:  16\n",
      "current minibatch:  17\n",
      "current minibatch:  18\n",
      "current minibatch:  19\n",
      "current minibatch:  20\n",
      "current minibatch:  21\n",
      "current minibatch:  22\n",
      "current minibatch:  23\n",
      "current minibatch:  24\n",
      "current minibatch:  25\n",
      "current minibatch:  26\n",
      "current minibatch:  27\n",
      "current minibatch:  28\n",
      "current minibatch:  29\n",
      "current minibatch:  30\n",
      "current minibatch:  31\n",
      "current minibatch:  32\n",
      "current minibatch:  33\n",
      "current minibatch:  34\n",
      "current minibatch:  35\n",
      "current minibatch:  36\n",
      "current minibatch:  37\n",
      "current minibatch:  38\n",
      "current minibatch:  39\n",
      "current minibatch:  40\n",
      "current minibatch:  41\n",
      "current minibatch:  42\n",
      "current minibatch:  43\n",
      "current minibatch:  44\n",
      "current minibatch:  45\n",
      "current minibatch:  46\n",
      "current minibatch:  47\n",
      "current minibatch:  48\n",
      "current minibatch:  49\n",
      "current minibatch:  50\n",
      "The test accuracy is 0.5178125\n"
     ]
    }
   ],
   "source": [
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = nn.DataParallel(model)\n",
    "batch_size = 64\n",
    "path1 = 'saved_models/Nov15/06_22PM.pt'\n",
    "path = 'lastModel.pt'\n",
    "fold1 = 'fold1.pt'\n",
    "fold2 = 'fold2.pt'\n",
    "\n",
    "model = torch.load(fold2)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "# with torch.cuda.device(dev0):\n",
    "#     t = t.cuda()\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = nn.DataParallel(model)\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#enter eval mode\n",
    "model.eval()\n",
    "\n",
    "def calculate_accu(outputs, labels, batch_size):\n",
    "    num_correct = torch.sum(torch.max(outputs, dim = 1)[1] == labels).item()\n",
    "    return num_correct / batch_size\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(128), transforms.CenterCrop(128), transforms.ToTensor()])\n",
    "test_dataset = loader('test.csv','/datasets/cs154-fa19-public/',transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "def per_class_model_performance(performances):\n",
    "    \n",
    "    perf_df = []\n",
    "    \n",
    "    #for each class, calculate accuracy, recall, precision and bcr\n",
    "    for i in range(len(performances)):\n",
    "        \n",
    "        cur_perf = performances[i]\n",
    "        accu, recall, precision, bcr = get_per_class_values(cur_perf)\n",
    "        \n",
    "        perf_df.append([accu, precision, recall, bcr])\n",
    "        \n",
    "    #make it to a dataframe\n",
    "    perf_df = pd.DataFrame(perf_df)\n",
    "    perf_df.columns = ['Accuracy', 'Precision', 'Recall', 'BCR']\n",
    "    \n",
    "    return perf_df\n",
    " \n",
    "\n",
    "#get measurement recall, accuracy, precision and bcr value for the current class\n",
    "def get_per_class_values(cur_perf):    \n",
    "    \n",
    "    tp = cur_perf['TP']\n",
    "    fp = cur_perf['FP']\n",
    "    tn = cur_perf['TN']\n",
    "    fn = cur_perf['FN']\n",
    "    \n",
    "    #accuracy\n",
    "    accu = (tp + tn)/(tp + tn + fp + fn)\n",
    "    \n",
    "    #recall\n",
    "    if tp + fn == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = tp / (tp + fn)\n",
    "    \n",
    "    #precision\n",
    "    if fp + tp == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (fp + tp)\n",
    "        \n",
    "    #bcr\n",
    "    bcr = (precision + recall) / 2\n",
    "    \n",
    "    return accu, recall, precision, bcr\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "#Apply to test set and test Performances\n",
    "all_class_performance = []\n",
    "test_accuracies = []\n",
    "\n",
    "#turn list into a sparse matrix\n",
    "def make_matrix(lst):\n",
    "    mat = []\n",
    "    for i in lst:\n",
    "        cur = [0] * 201\n",
    "        cur[i] = 1\n",
    "        mat.append(cur)\n",
    "    return np.array(mat)\n",
    "\n",
    "\n",
    "for i in range(201):\n",
    "    all_class_performance.append({'TP': 0, 'FP': 0, 'TN': 0, 'FN': 0})\n",
    "\n",
    "with torch.no_grad(): \n",
    "    \n",
    "    test_accu = 0\n",
    "    \n",
    "    for minibatch_count, (images, labels) in enumerate(test_loader, 0):\n",
    "        \n",
    "        print(\"current minibatch: \", minibatch_count)\n",
    "        # Put the minibatch data in CUDA Tensors and run on the GPU if supported\n",
    "        images, labels = images.to(device), labels.to(device) \n",
    "        outputs = model(images)\n",
    "        \n",
    "        test_accu += calculate_accu(outputs, labels, batch_size)\n",
    "        \n",
    "        predictions = torch.max(outputs, dim = 1)[1]\n",
    "\n",
    "        pred = make_matrix(predictions.tolist())\n",
    "        lab = make_matrix(labels.tolist())\n",
    "\n",
    "        for i in range(pred.shape[0]):\n",
    "            for j in range(201):\n",
    "                if (pred[i][j] == 1) and (lab[i][j] == 1):\n",
    "                    all_class_performance[j]['TP'] += 1\n",
    "                elif (pred[i][j] == 1) and (lab[i][j] == 0):\n",
    "                    all_class_performance[j]['FP'] += 1\n",
    "                elif (pred[i][j] == 0) and (lab[i][j] == 0):\n",
    "                    all_class_performance[j]['TN'] += 1\n",
    "                else:\n",
    "                    all_class_performance[j]['FN'] += 1\n",
    "                    \n",
    "    test_accuracies = (test_accu/minibatch_count)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ## Visualizations\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ### Training and Validation Loss Curves\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "print('The test accuracy is ' + str(test_accu/minibatch_count))\n",
    "\n",
    "#from baseline_copy  The test accuracy is 0.6184375\n",
    "#from baseline_copy1 The test accuracy is 0.6184375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fold2 = per_class_model_performance(all_class_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>BCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.990729</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.502232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.993820</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.094017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.997219</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.667582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.992274</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.244444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall       BCR\n",
       "0  1.000000   0.000000  0.000000  0.000000\n",
       "1  0.990729   0.535714  0.468750  0.502232\n",
       "2  0.993820   0.076923  0.111111  0.094017\n",
       "3  0.997219   0.692308  0.642857  0.667582\n",
       "4  0.992274   0.222222  0.266667  0.244444"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fold1 = per_class_model_performance(all_class_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>BCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.985476</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.341346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.996910</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.994438</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.439216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall       BCR\n",
       "0  1.000000   0.000000  0.000000  0.000000\n",
       "1  0.985476   0.307692  0.375000  0.341346\n",
       "2  0.996910   0.400000  0.222222  0.311111\n",
       "3  0.996910   0.666667  0.571429  0.619048\n",
       "4  0.994438   0.411765  0.466667  0.439216"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fold1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TOP 5 CLASSES for ZekeNet 2-fold X-Vldtn\n",
      "     Accuracy  Precision    Recall       BCR\n",
      "199  0.999536   0.845238  0.916667  0.880952\n",
      "91   0.998764   0.757143  0.642857  0.700000\n",
      "133  0.998764   0.875000  0.625000  0.750000\n",
      "47   0.998609   0.708333  0.950000  0.829167\n",
      "84   0.998455   0.750000  0.562500  0.656250\n",
      "\n",
      "  TOP 5 CLASSES for ZekeNet 2-fold X-Vldtn\n",
      "     Accuracy  Precision    Recall       BCR\n",
      "1    0.988103   0.421703  0.421875  0.421789\n",
      "21   0.987330   0.369748  0.451613  0.410680\n",
      "117  0.986712   0.168182  0.500000  0.334091\n",
      "109  0.986712   0.284512  0.283333  0.283923\n",
      "37   0.986557   0.356352  0.483333  0.419843\n"
     ]
    }
   ],
   "source": [
    "top, bottom = get_values(df_avg)\n",
    "print(\"  TOP 5 CLASSES for ZekeNet 2-fold X-Vldtn\")\n",
    "print(top)\n",
    "print()\n",
    "print(\"  BOT 5 CLASSES for ZekeNet 2-fold X-Vldtn\")\n",
    "print(bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_avg = pd.concat([df_fold1,df_fold2]).groupby(level=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>BCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.988103</td>\n",
       "      <td>0.421703</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.421789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.995365</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.202564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.997064</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.643315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.993356</td>\n",
       "      <td>0.316993</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.341830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall       BCR\n",
       "0  1.000000   0.000000  0.000000  0.000000\n",
       "1  0.988103   0.421703  0.421875  0.421789\n",
       "2  0.995365   0.238462  0.166667  0.202564\n",
       "3  0.997064   0.679487  0.607143  0.643315\n",
       "4  0.993356   0.316993  0.366667  0.341830"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(df):\n",
    "    sorted_accs = df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "    top_5 = sorted_accs[1:6]\n",
    "    bot_5 = sorted_accs[-5:]\n",
    "    return top_5, bot_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loader('test.csv','/datasets/cs154-fa19-public/')\n",
    "df_tst = dataset.frame\n",
    "\n",
    "classes = []\n",
    "classes.append('no classes for label 0')\n",
    "c = 0\n",
    "for images, labels in df:\n",
    "#     class_labels.append(labels)\n",
    "#     print(dataset[0])\n",
    "    \n",
    "    print(images.filename.find('test/'))\n",
    "    if c == 0:\n",
    "        break\n",
    "df_tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in df_tst.path:\n",
    "#     print(path)\n",
    "    i = path.find('test/') + 5\n",
    "    name = path[i:]\n",
    "#     print(name)\n",
    "    j = name.find('/')\n",
    "    name = name[:j]\n",
    "#     print(name)\n",
    "    if not name in classes:\n",
    "        classes.append(name)\n",
    "        \n",
    "df_tst.label.value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(best5, overall=False):\n",
    "    \n",
    "    #display average overall metrics\n",
    "    if overall:\n",
    "        dosomething\n",
    "        \n",
    "    \n",
    "    if best5:\n",
    "        #display metrics for top 5 classes\n",
    "        hi\n",
    "    else:\n",
    "        #display metrics for worst 5 classes\n",
    "        hi\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_score(t, y):\n",
    "    '''\n",
    "    t: ground truth\n",
    "    y: predicted label\n",
    "    '''\n",
    "    TP[t]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(test_loader))\n",
    "classes_right = [0] * 201\n",
    "# classes_right[0] = 1\n",
    "# class_images = []\n",
    "# for images, labels in dataset:\n",
    "#     class_labels.append(labels)\n",
    "# #     class_images.append(images)\n",
    "    \n",
    "# # print(np.amax(class_labels), np.amin(class_labels))\n",
    "# # c = 0\n",
    "\n",
    "# self.model = model \n",
    "# Since if the model is wrapped by the `DataParallel` class, you won't be able to access its attributes\n",
    "# unless you write `model.module` which breaks the code compatibility. We use `model_attr_accessor` for attributes\n",
    "# accessing only.\n",
    "# model = model.module\n",
    "\n",
    "classes_count = [0] * 201\n",
    "# print(classes_count, len(classes_count))\n",
    "# print(classes_count)\n",
    "\n",
    "\n",
    "\n",
    "pred_classes = []\n",
    "accu = 0\n",
    "with torch.no_grad():\n",
    "    for i, (images, labels) in enumerate(test_loader, 0):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = model(images)\n",
    "        t = labels.item()\n",
    "        classes_count[t] += 1\n",
    "        y_i = torch.argmax(y).item()\n",
    "        pred_classes.append(y_i)\n",
    "#         print(i)\n",
    "#         print(images)\n",
    "#         print(labels)\n",
    "#         print(labels.item())\n",
    "        if t == y_i:\n",
    "            accu += 1\n",
    "            classes_right[t] += 1\n",
    "            \n",
    "# print(pred_classes)\n",
    "print(np.amax(pred_classes), np.amin(pred_classes))\n",
    "# # print(y)\n",
    "# # print(torch.argmax(y).item())\n",
    "print(\"accuracy: \", (accu/len(dataset)))\n",
    "print(accu)\n",
    "classes_accu = np.array(classes_right[1:]) / np.array(classes_count[1:])\n",
    "#b = best, w = worst\n",
    "b = np.argmax(classes_accu)\n",
    "w = np.argmin(classes_accu)\n",
    "\n",
    "print(\"best class performace with (accuracy): \", b+1, \"(\" + str(classes_accu[b]) + \")\", np.amax(classes_accu), \" --- \" + str(classes_right[b+1]) + \"/\" + str(classes_count[b+1]) + \" right\")\n",
    "\n",
    "print(\"worst class performace with (accuracy): \", w+1, \"(\" + str(classes_accu[w]) + \")\", np.amin(classes_accu), \" --- \" + str(classes_right[w+1]) + \"/\" + str(classes_count[w+1]) + \" right\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
